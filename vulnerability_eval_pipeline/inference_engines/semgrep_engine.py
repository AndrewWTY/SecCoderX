"""
Semgrep Static Analysis Engine for Vulnerability Detection
Provides Semgrep-based static analysis as a baseline for comparison with LLM approaches.
Multi-language static analysis using pattern-based rules.
"""

import json
import os
import signal
import subprocess
import tempfile
import shutil
import threading
from typing import List, Dict, Any, Optional, Tuple
from dataclasses import dataclass
from concurrent.futures import ThreadPoolExecutor, wait, FIRST_COMPLETED
from tqdm import tqdm

from .base import BaseInferenceEngine, InferenceResult


# Global flag for graceful shutdown
_shutdown_requested = threading.Event()


@dataclass
class SemgrepConfig:
    """Configuration for Semgrep analysis"""
    semgrep_path: str
    threads: int
    timeout: int
    config: str  # Ruleset config (e.g., "p/security-audit")
    temp_dir: Optional[str]


class SemgrepEngine(BaseInferenceEngine):
    """
    Inference engine using Semgrep for multi-language static analysis vulnerability detection.

    Unlike LLM engines, Semgrep:
    - Doesn't use prompts or templates
    - Analyzes code directly via pattern-based rules
    - Produces deterministic results (no temperature/sampling)
    - Supports 35+ languages (auto-detected by file extension)

    Key features:
    - Pattern-based rule matching
    - Configurable rulesets (p/security-audit, p/ci, custom)
    - Faster than CodeQL (~2-5 seconds per snippet)
    - JSON output format
    """

    # Map language_suffix/name to file extensions
    # Covers all common variations in naming
    EXTENSION_MAP = {
        # Python
        'python': '.py',
        'Python': '.py',
        'py': '.py',
        # JavaScript/TypeScript
        'javascript': '.js',
        'JavaScript': '.js',
        'js': '.js',
        'JS': '.js',
        'typescript': '.ts',
        'TypeScript': '.ts',
        'ts': '.ts',
        # Java
        'java': '.java',
        'Java': '.java',
        # C/C++
        'c': '.c',
        'C': '.c',
        'cpp': '.cpp',
        'c++': '.cpp',
        'C++': '.cpp',
        'Cpp': '.cpp',
        # C#
        'csharp': '.cs',
        'c#': '.cs',
        'C#': '.cs',
        'cs': '.cs',
        # Go
        'go': '.go',
        'Go': '.go',
        'golang': '.go',
        # Ruby
        'ruby': '.rb',
        'Ruby': '.rb',
        'rb': '.rb',
        # PHP
        'php': '.php',
        'PHP': '.php',
        # Rust
        'rust': '.rs',
        'Rust': '.rs',
        'rs': '.rs',
        # Kotlin
        'kotlin': '.kt',
        'Kotlin': '.kt',
        'kt': '.kt',
        # Swift
        'swift': '.swift',
        'Swift': '.swift',
        # Scala
        'scala': '.scala',
        'Scala': '.scala',
        # Bash/Shell
        'bash': '.sh',
        'Bash': '.sh',
        'shell': '.sh',
        'sh': '.sh',
        # HTML/XML
        'html': '.html',
        'HTML': '.html',
        'xml': '.xml',
        'XML': '.xml',
        # YAML/JSON
        'yaml': '.yaml',
        'YAML': '.yaml',
        'yml': '.yml',
        'json': '.json',
        'JSON': '.json',
    }

    def __init__(
        self,
        semgrep_path: str = None,
        threads: int = 8,
        timeout: int = 120,
        config: str = "p/security-audit",
        temp_dir: str = None,
        output_model_name: str = None,
        **kwargs  # Accept and ignore LLM-specific kwargs like template
    ):
        """
        Initialize the Semgrep engine.

        Args:
            semgrep_path: Path to semgrep CLI (auto-detect if None)
            threads: Number of parallel analysis threads
            timeout: Timeout per code snippet (seconds)
            config: Semgrep ruleset config (default: p/security-audit)
            temp_dir: Custom temporary directory
            output_model_name: Name for output files
        """
        # Semgrep doesn't use templates, pass None to parent
        super().__init__(
            template=None,
            system_prompt_file=None,
            output_model_name=output_model_name or 'semgrep-security',
            max_prompt_tokens=None
        )

        # Find and validate Semgrep CLI
        self.semgrep_path = semgrep_path or self._find_semgrep()
        self._validate_semgrep()

        # Store configuration
        self.config = SemgrepConfig(
            semgrep_path=self.semgrep_path,
            threads=threads,
            timeout=timeout,
            config=config,
            temp_dir=temp_dir
        )

        self.logger.info(f"Initialized Semgrep engine")
        self.logger.info(f"  Semgrep path: {self.semgrep_path}")
        self.logger.info(f"  Ruleset config: {config}")
        self.logger.info(f"  Parallel threads: {threads}")

    def _find_semgrep(self) -> str:
        """Auto-detect Semgrep CLI path"""
        # Try common locations
        common_paths = [
            'semgrep',  # In PATH
            os.path.expanduser('~/.local/bin/semgrep'),
            '/usr/local/bin/semgrep',
            '/usr/bin/semgrep',
            '/opt/homebrew/bin/semgrep',  # macOS homebrew
        ]

        for path in common_paths:
            try:
                result = subprocess.run(
                    [path, '--version'],
                    capture_output=True,
                    text=True,
                    timeout=10
                )
                if result.returncode == 0:
                    self.logger.info(f"Found Semgrep at: {path}")
                    return path
            except (subprocess.TimeoutExpired, FileNotFoundError, PermissionError):
                continue

        raise RuntimeError(
            "Semgrep CLI not found. Please install Semgrep:\n"
            "  pip install semgrep\n"
            "  OR\n"
            "  brew install semgrep (macOS)\n"
            "Or specify --semgrep_path /path/to/semgrep"
        )

    def _validate_semgrep(self) -> None:
        """Validate Semgrep installation"""
        try:
            result = subprocess.run(
                [self.semgrep_path, '--version'],
                capture_output=True,
                text=True,
                timeout=10
            )
            if result.returncode != 0:
                raise RuntimeError(f"Semgrep validation failed: {result.stderr}")
            self.logger.info(f"Semgrep version: {result.stdout.strip()}")
        except subprocess.TimeoutExpired:
            raise RuntimeError("Semgrep validation timed out")
        except FileNotFoundError:
            raise RuntimeError(f"Semgrep not found at: {self.semgrep_path}")

    def _get_file_extension(self, language: str) -> str:
        """Get appropriate file extension for language"""
        return self.EXTENSION_MAP.get(language, '.txt')

    def _prepare_code_snippet(
        self,
        code: str,
        language: str,
        index: int,
        base_temp_dir: str
    ) -> str:
        """
        Write code snippet to a temporary file for Semgrep analysis.

        Returns:
            Path to the temporary source file
        """
        extension = self._get_file_extension(language)

        # Create unique directory for this snippet
        snippet_dir = os.path.join(base_temp_dir, f"snippet_{index}")
        os.makedirs(snippet_dir, exist_ok=True)

        # Write code to file with correct extension
        source_file = os.path.join(snippet_dir, f"code{extension}")
        with open(source_file, 'w', encoding='utf-8') as f:
            f.write(code)

        return source_file

    def _run_subprocess_interruptible(
        self,
        cmd: List[str],
        timeout: int,
        operation_name: str
    ) -> Tuple[bool, str, str]:
        """
        Run a subprocess with support for graceful interruption.

        Returns:
            Tuple of (success: bool, stdout: str, error_message: str)
        """
        global _shutdown_requested

        # Check if shutdown already requested
        if _shutdown_requested.is_set():
            return False, "", "Shutdown requested"

        process = None
        try:
            process = subprocess.Popen(
                cmd,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True
            )

            # Poll with small intervals to check shutdown flag
            elapsed = 0
            poll_interval = 0.5
            while elapsed < timeout:
                if _shutdown_requested.is_set():
                    # Terminate the process
                    process.terminate()
                    try:
                        process.wait(timeout=2)
                    except subprocess.TimeoutExpired:
                        process.kill()
                        process.wait()
                    return False, "", "Shutdown requested"

                retcode = process.poll()
                if retcode is not None:
                    # Process finished
                    stdout, stderr = process.communicate()
                    # Semgrep returns 0 on success (even with findings)
                    if retcode == 0:
                        return True, stdout, ""
                    # Check for actual errors
                    if "error" in stderr.lower():
                        return False, stdout, f"{operation_name} failed: {stderr[:200]}"
                    # Return code 1 may indicate findings, which is fine
                    return True, stdout, ""

                import time
                time.sleep(poll_interval)
                elapsed += poll_interval

            # Timeout reached
            process.terminate()
            try:
                process.wait(timeout=2)
            except subprocess.TimeoutExpired:
                process.kill()
                process.wait()
            return False, "", f"{operation_name} timed out"

        except Exception as e:
            if process is not None:
                try:
                    process.kill()
                    process.wait()
                except:
                    pass
            return False, "", f"{operation_name} error: {str(e)}"

    def _run_analysis(self, source_file: str, output_file: str) -> Tuple[bool, str]:
        """
        Run Semgrep analysis on a single source file.
        Output results in JSON format for parsing.

        Returns:
            Tuple of (success: bool, error_message: str)
        """
        cmd = [
            self.semgrep_path,
            'scan',
            '--config', self.config.config,
            '--json',
            '--json-output', output_file,
            '--quiet',  # Reduce noise
            source_file
        ]

        success, _, error = self._run_subprocess_interruptible(
            cmd, self.config.timeout, "Semgrep analysis"
        )
        return success, error

    def _parse_json_results(self, output_file: str) -> Dict[str, Any]:
        """
        Parse Semgrep JSON results - check if any entries exist in results array.

        JSON structure:
        {
            "version": "...",
            "results": [...],  # Security findings
            "errors": [],
            "paths": {...},
            "time": {...}
        }

        If any entry in results array -> vulnerable.

        Returns:
            Dict with: is_vulnerable, findings_count, error
        """
        try:
            if not os.path.exists(output_file):
                # No output file means no findings
                return {
                    'is_vulnerable': False,
                    'findings_count': 0,
                    'error': None
                }

            with open(output_file, 'r', encoding='utf-8') as f:
                content = f.read()

            if not content or not content.strip():
                # Empty output means no findings
                return {
                    'is_vulnerable': False,
                    'findings_count': 0,
                    'error': None
                }

            data = json.loads(content)
            results = data.get('results', [])
            findings_count = len(results)

            return {
                'is_vulnerable': findings_count > 0,
                'findings_count': findings_count,
                'error': None
            }

        except json.JSONDecodeError as e:
            return {
                'is_vulnerable': False,
                'findings_count': 0,
                'error': f"JSON parse error: {str(e)}"
            }
        except Exception as e:
            return {
                'is_vulnerable': False,
                'findings_count': 0,
                'error': str(e)
            }

    def _result_to_response(self, analysis_result: Dict[str, Any]) -> str:
        """
        Convert Semgrep analysis result to evaluator-compatible response.

        Uses [[YES]]/[[NO]] format for compatibility with existing evaluator.
        Simple logic: any entries in results array -> vulnerable
        """
        error = analysis_result.get('error')
        if error:
            return f"[ANALYSIS_ERROR: {error}] Unable to determine vulnerability status."

        is_vulnerable = analysis_result.get('is_vulnerable', False)
        findings_count = analysis_result.get('findings_count', 0)

        if is_vulnerable:
            return f"[[YES]]\n\nSemgrep detected {findings_count} security issue(s)."
        else:
            return "[[NO]]\n\nSemgrep did not detect any security vulnerabilities."

    def _analyze_single_snippet(
        self,
        code: str,
        language: str,
        index: int,
        base_temp_dir: str
    ) -> Dict[str, Any]:
        """Analyze a single code snippet end-to-end."""
        global _shutdown_requested

        # Check if shutdown requested before starting
        if _shutdown_requested.is_set():
            return {
                'is_vulnerable': False,
                'findings_count': 0,
                'error': 'Shutdown requested'
            }

        # Paths for this snippet
        snippet_dir = os.path.join(base_temp_dir, f"snippet_{index}")
        output_file = os.path.join(base_temp_dir, f"results_{index}.json")

        try:
            # Step 1: Write code to temp file with correct extension
            source_file = self._prepare_code_snippet(code, language, index, base_temp_dir)

            # Step 2: Run Semgrep analysis (outputs JSON)
            success, error = self._run_analysis(source_file, output_file)
            if not success:
                return {'is_vulnerable': False, 'findings_count': 0, 'error': error}

            # Step 3: Parse JSON results (any entry = vulnerable)
            return self._parse_json_results(output_file)

        finally:
            # Cleanup snippet-specific files
            if os.path.exists(snippet_dir):
                shutil.rmtree(snippet_dir, ignore_errors=True)
            if os.path.exists(output_file):
                try:
                    os.remove(output_file)
                except:
                    pass

    def run_inference(
        self,
        prompts: List[str],
        temperature: float = 0.0,
        max_tokens: int = 4096,
        data: List[Dict[str, Any]] = None,
        **kwargs
    ) -> List[List[str]]:
        """
        Run Semgrep analysis on code snippets.

        Note: Unlike LLM engines, Semgrep requires the 'data' parameter
        containing 'code' and 'language_suffix' (or 'language_name') fields.

        Handles Ctrl+C gracefully by:
        - Cancelling pending futures
        - Terminating running subprocesses
        - Cleaning up temporary files
        """
        global _shutdown_requested
        _shutdown_requested.clear()

        if data is None:
            raise ValueError("Semgrep engine requires 'data' parameter")

        base_temp_dir = tempfile.mkdtemp(
            prefix='semgrep_analysis_',
            dir=self.config.temp_dir
        )

        responses = []
        executor = None
        pbar = None

        # Store original signal handler
        original_sigint = signal.getsignal(signal.SIGINT)
        original_sigterm = signal.getsignal(signal.SIGTERM)

        def signal_handler(signum, frame):
            """Handle interrupt signals gracefully"""
            self.logger.warning("\nInterrupt received. Shutting down gracefully...")
            _shutdown_requested.set()
            # Restore original handler to allow force quit on second Ctrl+C
            signal.signal(signal.SIGINT, original_sigint)
            signal.signal(signal.SIGTERM, original_sigterm)

        try:
            # Install signal handlers
            signal.signal(signal.SIGINT, signal_handler)
            signal.signal(signal.SIGTERM, signal_handler)

            executor = ThreadPoolExecutor(max_workers=self.config.threads)
            futures = {}

            for i, item in enumerate(data):
                if _shutdown_requested.is_set():
                    break
                code = item.get('code', '')
                # Use language_suffix for language detection, fallback to language_name
                language = item.get('language_suffix', item.get('language_name', 'python'))
                future = executor.submit(
                    self._analyze_single_snippet,
                    code, language, i, base_temp_dir
                )
                futures[future] = i

            # Collect results in order
            results = [None] * len(data)
            completed_count = 0

            pbar = tqdm(total=len(futures), desc="Semgrep Analysis")

            pending = set(futures.keys())
            while pending and not _shutdown_requested.is_set():
                # Wait for at least one future to complete, with timeout to check shutdown flag
                done, pending = wait(pending, timeout=0.5, return_when=FIRST_COMPLETED)

                for future in done:
                    idx = futures[future]
                    try:
                        result = future.result(timeout=0.1)
                        results[idx] = self._result_to_response(result)
                    except Exception as e:
                        self.logger.error(f"Error analyzing snippet {idx}: {e}")
                        results[idx] = f"[ANALYSIS_ERROR: {e}]"

                    completed_count += 1
                    pbar.update(1)

            # Handle shutdown - cancel remaining futures
            if _shutdown_requested.is_set():
                self.logger.warning(f"Cancelling {len(pending)} pending tasks...")
                for future in pending:
                    future.cancel()
                # Fill remaining results with error message
                for future in pending:
                    idx = futures[future]
                    if results[idx] is None:
                        results[idx] = "[ANALYSIS_CANCELLED: Shutdown requested]"
                pbar.close()
                raise KeyboardInterrupt("Analysis interrupted by user")

            pbar.close()

            # Filter out None results (shouldn't happen but be safe)
            responses = [[r if r is not None else "[ANALYSIS_ERROR: Unknown error]"] for r in results]

        except KeyboardInterrupt:
            self.logger.warning("Semgrep analysis interrupted by user")
            raise
        finally:
            # Restore original signal handlers
            signal.signal(signal.SIGINT, original_sigint)
            signal.signal(signal.SIGTERM, original_sigterm)

            # Shutdown executor
            if executor is not None:
                self.logger.info("Shutting down thread pool...")
                executor.shutdown(wait=False, cancel_futures=True)

            # Close progress bar if still open
            if pbar is not None:
                try:
                    pbar.close()
                except:
                    pass

            # Clean up temp directory
            self.logger.info("Cleaning up temporary files...")
            shutil.rmtree(base_temp_dir, ignore_errors=True)

            self.logger.info("Cleanup complete")

        return responses

    def run_inference_pipeline(
        self,
        data_path: str,
        output_dir: str,
        temperature: float = 0.0,
        max_tokens: int = 4096,
        max_samples: int = None,
        seed: int = 42,
        balanced_sampling: bool = True,
        prompt_column: str = None,
        num_samples: int = 1,
        **kwargs
    ) -> InferenceResult:
        """Run complete Semgrep analysis pipeline."""

        # Setup output directory
        dataset_name = os.path.splitext(os.path.basename(data_path))[0]
        dataset_output_dir = os.path.join(output_dir, dataset_name)
        os.makedirs(dataset_output_dir, exist_ok=True)

        # Load data
        self.logger.info(f"Loading data from {data_path}")
        data = self.load_data(data_path)
        original_count = len(data)

        # Collect language statistics (use language_suffix, fallback to language_name)
        language_counts = {}
        for item in data:
            lang = item.get('language_suffix', item.get('language_name', 'unknown'))
            language_counts[lang] = language_counts.get(lang, 0) + 1

        lang_summary = ", ".join([f"{lang}: {count}" for lang, count in sorted(language_counts.items())])
        self.logger.info(f"Languages to analyze: {lang_summary}")

        if len(data) == 0:
            raise ValueError("No samples found in dataset")

        # Sample if requested
        if max_samples and len(data) > max_samples:
            if balanced_sampling:
                data = self.balanced_sample(data, max_samples, seed)
            else:
                data = data[:max_samples]
            self.logger.info(f"Sampled to {len(data)} samples")

        # Create placeholder prompts (Semgrep doesn't use prompts but format needs them)
        prompts = [f"[Semgrep Analysis #{i}]" for i in range(len(data))]

        # Run analysis
        self.logger.info(f"Starting Semgrep analysis on {len(data)} samples...")
        responses = self.run_inference(prompts=prompts, data=data)

        # Create result
        result = InferenceResult(
            prompts=prompts,
            responses=responses,
            metadata=data
        )

        # Save results
        model_name = self.output_model_name
        inference_file = os.path.join(
            dataset_output_dir,
            f"{model_name}_semgrep_1_inference_results.jsonl"
        )

        inference_params = {
            'backend': 'semgrep',
            'config': self.config.config,
            'threads': self.config.threads,
            'output_format': 'json'
        }

        self.save_inference_results(prompts, responses, data, inference_file, inference_params)
        self.logger.info(f"Results saved to {inference_file}")

        return result
